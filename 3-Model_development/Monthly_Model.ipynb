{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Model Development and Evaluation using Mean Monthly Values\n",
    "The following notebook will explore how a multiple linear regression can explore the monthly mean concentration of four pollutants with the mean weather data and the upstream and oil and gas activity data.\n",
    "\n",
    "## Definition of Models\n",
    "A set of features for each pollutant were selected based on the correlations shown in the heat map and the scatter plots.\n",
    "\n",
    "**Y1: SO2**\n",
    "X1: Temperature, X2: Wind speed, X3: Humidity, X4: Gas produced\n",
    "\n",
    "**Y2: TRS**\n",
    "X1: Wind speed, X2: Wind direction, X3: Depth drilled, X4: Gas produced\n",
    "\n",
    "**Y3: NO2**\n",
    "X1: Temperature, X2: Wind direction, X3: Wind speed, X4: Humidity, X5: Depth drilled, X6: Gas produced\n",
    "\n",
    "**Y4: O3**\n",
    "X1: Temperature, X2: Wind direction, X3: Wind speed, X4: Humidity, X5: Depth drilled, X6: Gas produced\n",
    "\n",
    "### Data Splitting, Loss Functions & Cross-Validation\n",
    "\n",
    "**Data Splitting**\n",
    "The dataset will be split into a training and a testing dataset. The test dataset will include approximately 1/3 of the dataset to ensure that both the testing and the training sets are representative of the smaller-sized dataset.\n",
    "\n",
    "**Feature Selection**\n",
    "The correlation heat maps will be used to select the dependant variables. The features will not be scaled as these are not large datasets, and therefore the time to converge is not a concern.\n",
    "\n",
    "**Loss Functions**\n",
    "The sklearn LinearRegression fits a linear model that minimizes the Root Mean Squared Error (RMSE) loss function. This loss function cannot be changed. This loss function has the model learn the outlier data but applies high penalties to incorrect predictions on outlier data points.\n",
    "\n",
    "**Cross Validation**\n",
    "The train-validation-test split will not be used. The model is working with a smaller dataset. Therefore, the data will only be split into a training and a testing set. By introducing a validation set, the smaller size of the training, validation, and testing set will be less representative of the sample data.\n",
    "A Grid Search Cross-Validation will be used. This grid will explore different parameters for the Linear Regression, including the intercept and is the regressors X will be normalized before regression. A 5-fold split will be used in this grid search to cross validate.\n",
    "\n",
    "**Evaluation & Testing**\n",
    "The model will be evaluated using the R^2^ score. The R^2^ measures the proportion of variance in the dependant variable that is predictable from the independent variables and is commonly used for linear regression. A higher R^2^ value indicates a better fit. Residual plots will also be used to ensure no transformations are required for the data and a linear model was the best choice (versus a polynomial).\n",
    "\n",
    "**Other Possible Models for Future Consideration**\n",
    "Sklearn offers another linear regression: the Huber Regressor that is a linear regression more robust to outliers and the Lasso model that that combines L1 and L2 loss functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Import third party libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import linear_model as lm\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from scipy.stats import circmean\n",
    "import os"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Read in monthly df\n",
    "month_mean = pd.read_csv('month_mean.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model 1: SO2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Split df into x and y\n",
    "X =  month_mean.filter(['TEMP_MEAN_(C)', 'WSPD_SCLR_(M/S)', 'HUMIDITY_(%)', 'gas_prod_vol_m3'], axis=1)\n",
    "y = month_mean.filter(['SO2'], axis=1)\n",
    "\n",
    "# Split the data into a training and a testing set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=0)\n",
    "\n",
    "# Print test and trainning sizes\n",
    "print('Train {}%'.format(X_train.shape[0] / month_mean.shape[0] * 100))\n",
    "print('Test {}%'.format(X_test.shape[0] / month_mean.shape[0] * 100))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Create a LinearRegression object and name it linear_model\n",
    "linear_model = lm.LinearRegression()\n",
    "\n",
    "# Define parameters to explore\n",
    "parameters = [{'fit_intercept':[True, False],\n",
    "               'normalize':[True, False]}]\n",
    "\n",
    "# Hyper-Parameter Tuning and Cross Validation\n",
    "grid_search = GridSearchCV(estimator=linear_model,\n",
    "                           param_grid=parameters,\n",
    "                           scoring = 'r2',\n",
    "                           cv = 5,\n",
    "                           verbose =0,\n",
    "                           return_train_score=True)\n",
    "# Fit model to training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Predict training data y using model\n",
    "y_fitted = grid_search.predict(X_train)\n",
    "\n",
    "# Print the r-squared value\n",
    "print(r2_score(y_train, y_fitted))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Plot the residuals\n",
    "residuals = y_train - y_fitted\n",
    "ax = sns.regplot(x=y_train, y=residuals['SO2'])\n",
    "ax.set_xlabel('SO2 (training data)')\n",
    "ax.set_ylabel('Residuals (Actual SO2 - Predicted SO2')\n",
    "plt.title('Residual Plot for SO2 Training Data')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Now predict the test values and calculate the r-squared score\n",
    "y_fitted = grid_search.predict(X_test)\n",
    "print(r2_score(y_test, y_fitted))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model 2: TRS"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Split df into x and y\n",
    "X =  month_mean.filter(['WSPD_SCLR_(M/S)', 'WDIR_VECT_(DEG)', 'Depth_per_day', 'gas_prod_vol_m3'], axis=1)\n",
    "y = month_mean.filter(['TRS'], axis=1)\n",
    "\n",
    "# Split the data into a training and a testing set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=0)\n",
    "\n",
    "# Print test and trainning sizes\n",
    "print('Train {}%'.format(X_train.shape[0] / month_mean.shape[0] * 100))\n",
    "print('Test {}%'.format(X_test.shape[0] / month_mean.shape[0] * 100))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Create a LinearRegression object and name it linear_model\n",
    "linear_model = lm.LinearRegression()\n",
    "\n",
    "# Define parameters to explore\n",
    "parameters = [{'fit_intercept':[True, False],\n",
    "               'normalize':[True, False]}]\n",
    "\n",
    "# Hyper-Parameter Tuning and Cross Validation\n",
    "grid_search = GridSearchCV(estimator=linear_model,\n",
    "                           param_grid=parameters,\n",
    "                           scoring = 'r2',\n",
    "                           cv = 5,\n",
    "                           verbose =0,\n",
    "                           return_train_score=True)\n",
    "# Fit model to training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Predict training data y using model\n",
    "y_fitted = grid_search.predict(X_train)\n",
    "\n",
    "# Print the r-squared value\n",
    "print(r2_score(y_train, y_fitted))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Plot the residuals\n",
    "residuals = y_train - y_fitted\n",
    "ax = sns.regplot(x=y_train, y=residuals['TRS'])\n",
    "ax.set_xlabel('TRS (training data)')\n",
    "ax.set_ylabel('Residuals (Actual TRS - Predicted TRS')\n",
    "plt.title('Residual Plot for TRS Training Data')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Now predict the test values and calculate the r-squared score\n",
    "y_fitted = grid_search.predict(X_test)\n",
    "print(r2_score(y_test, y_fitted))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model 3: NO2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Split df into x and y\n",
    "X =  month_mean.filter(['TEMP_MEAN_(C)', 'WDIR_VECT_(DEG)', 'WSPD_SCLR_(M/S)', 'HUMIDITY_(%)', 'Depth_per_day','gas_prod_vol_m3'], axis=1)\n",
    "y = month_mean.filter(['NO2'], axis=1)\n",
    "\n",
    "# Split the data into a training and a testing set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=10)\n",
    "\n",
    "# Print test and trainning sizes\n",
    "print('Train {}%'.format(X_train.shape[0] / month_mean.shape[0] * 100))\n",
    "print('Test {}%'.format(X_test.shape[0] / month_mean.shape[0] * 100))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Create a LinearRegression object and name it linear_model\n",
    "linear_model = lm.LinearRegression()\n",
    "\n",
    "# Define parameters to explore\n",
    "parameters = [{'fit_intercept':[True, False],\n",
    "               'normalize':[True, False]}]\n",
    "\n",
    "# Hyper-Parameter Tuning and Cross Validation\n",
    "grid_search = GridSearchCV(estimator=linear_model,\n",
    "                           param_grid=parameters,\n",
    "                           scoring = 'r2',\n",
    "                           cv = 5,\n",
    "                           verbose =0,\n",
    "                           return_train_score=True)\n",
    "# Fit model to training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Predict training data y using model\n",
    "y_fitted = grid_search.predict(X_train)\n",
    "\n",
    "# Print the r-squared value\n",
    "print(r2_score(y_train, y_fitted))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Plot the residuals\n",
    "residuals = y_train - y_fitted\n",
    "ax = sns.regplot(x=y_train, y=residuals['NO2'])\n",
    "ax.set_xlabel('NO2 (training data)')\n",
    "ax.set_ylabel('Residuals (Actual NO2 - Predicted NO2')\n",
    "plt.title('Residual Plot for NO2 Training Data')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Now predict the test values and calculate the r-squared score\n",
    "y_fitted = grid_search.predict(X_test)\n",
    "print(r2_score(y_test, y_fitted))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model 4: O3"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Split df into x and y\n",
    "X =  month_mean.filter(['TEMP_MEAN_(C)', 'WDIR_VECT_(DEG)', 'WSPD_SCLR_(M/S)', 'HUMIDITY_(%)','gas_prod_vol_m3'], axis=1)\n",
    "y = month_mean.filter(['O3'], axis=1)\n",
    "\n",
    "# Split the data into a training and a testing set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=0)\n",
    "\n",
    "# Print test and trainning sizes\n",
    "print('Train {}%'.format(X_train.shape[0] / month_mean.shape[0] * 100))\n",
    "print('Test {}%'.format(X_test.shape[0] / month_mean.shape[0] * 100))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Create a LinearRegression object and name it linear_model\n",
    "linear_model = lm.LinearRegression()\n",
    "\n",
    "# Define parameters to explore\n",
    "parameters = [{'fit_intercept':[True, False],\n",
    "               'normalize':[True, False]}]\n",
    "\n",
    "# Hyper-Parameter Tuning and Cross Validation\n",
    "grid_search = GridSearchCV(estimator=linear_model,\n",
    "                           param_grid=parameters,\n",
    "                           scoring = 'r2',\n",
    "                           cv = 5,\n",
    "                           verbose =0,\n",
    "                           return_train_score=True)\n",
    "# Fit model to training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Predict training data y using model\n",
    "y_fitted = grid_search.predict(X_train)\n",
    "\n",
    "# Print the r-squared value\n",
    "print(r2_score(y_train, y_fitted))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Plot the residuals\n",
    "residuals = y_train - y_fitted\n",
    "ax = sns.regplot(x=y_train, y=residuals['O3'])\n",
    "ax.set_xlabel('O3 (training data)')\n",
    "ax.set_ylabel('Residuals (Actual O3 - Predicted O3')\n",
    "plt.title('Residual Plot for O3 Training Data')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Now predict the test values and calculate the r-squared score\n",
    "y_fitted = grid_search.predict(X_test)\n",
    "print(r2_score(y_test, y_fitted))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}